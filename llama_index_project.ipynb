{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PDJz3RLx1wgj"
      },
      "source": [
        "## Installing the Packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k4gwMNLb6wOG",
        "outputId": "0a93c340-b158-42a7-e803-483f318fd602"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/56.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.4/7.4 MB\u001b[0m \u001b[31m57.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m997.8/997.8 kB\u001b[0m \u001b[31m33.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.9/72.9 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m62.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m394.9/394.9 kB\u001b[0m \u001b[31m23.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.1/149.1 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m52.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m48.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.1/211.1 kB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m55.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37.9/37.9 MB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.4/9.4 MB\u001b[0m \u001b[31m92.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.3/81.3 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m180.2/180.2 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m362.9/362.9 kB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.9/141.9 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.8/295.8 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m37.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.6/97.6 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m476.0/476.0 kB\u001b[0m \u001b[31m26.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.9/318.9 kB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for html2text (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for tinysegmenter (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for spider-client (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for feedfinder2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for jieba3k (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for sgmllib3k (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip -q install llama-index langchain llama-index-readers-web llama-index-embeddings-langchain llama-index-llms-huggingface langchain-community"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NxmKD__W19TL"
      },
      "source": [
        "## Providing Access Token\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ykax0sfbPdr_",
        "outputId": "a806d804-d7b9-4caa-e9d7-69ac7a097d16"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "··········\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from getpass import getpass\n",
        "HF_TOKEN = getpass()\n",
        "os.environ['HUGGINGFACEHUB_API_TOKEN'] = HF_TOKEN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wPwX3az42IC5"
      },
      "source": [
        "## Importing the required Packages\n",
        "- Vector Store Index\n",
        "- Simple Directory Reader\n",
        "- Simple Web Page Reader\n",
        "- Service Context\n",
        "- Storage Context\n",
        "- Storing\n",
        "- Node Parsers\n",
        "- Sentence Splitters\n",
        "- Huggingface Embeddings\n",
        "- Huggingface Inference API"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "kY3xwHErRpOE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "545e0ceb-0a84-47bb-c4da-d72e402ad5c4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pydantic/_internal/_fields.py:161: UserWarning: Field \"model_id\" has conflict with protected namespace \"model_\".\n",
            "\n",
            "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/pydantic/_internal/_fields.py:161: UserWarning: Field \"model_name\" has conflict with protected namespace \"model_\".\n",
            "\n",
            "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/pydantic/_internal/_fields.py:161: UserWarning: Field \"model_kwargs\" has conflict with protected namespace \"model_\".\n",
            "\n",
            "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader\n",
        "from llama_index.readers.web import SimpleWebPageReader\n",
        "from llama_index.core import ServiceContext, StorageContext,load_index_from_storage\n",
        "from llama_index.core.node_parser import SimpleNodeParser, MarkdownNodeParser, SentenceSplitter\n",
        "from langchain.embeddings import HuggingFaceInferenceAPIEmbeddings\n",
        "from llama_index.embeddings.langchain import LangchainEmbedding\n",
        "from llama_index.llms.huggingface import HuggingFaceInferenceAPI"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SKukhuXL75kr"
      },
      "source": [
        "## Storing Context\n",
        "- defining the llm end embedding model\n",
        "- storing the context using Indexing\n",
        "- retrieving the context from the storage context"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SHP897IX-7xa"
      },
      "source": [
        "### Define the:\n",
        "- **Persist Directory** - The persist directory in LlamaIndex is the location on disk where the indexed data and metadata are stored to avoid the time and cost of re-indexing the data.\n",
        "- **LLM Model** - LLM Model uses the query and the retrieved documents to generate a response\n",
        "- **Embedding Model** - Embedding Model generates vector embeddings which are to be stored in a vector store."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "jW6cEo5S-67Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8ac277a0-2ec5-4d5b-96b0-19f9e9c91102"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-6-c44059824592>:7: DeprecationWarning: Call to deprecated class HuggingFaceInferenceAPI. (Deprecated in favor of `HuggingFaceInferenceAPI` from `llama-index-llms-huggingface-api` which should be used instead.)\n",
            "  Settings.llm = HuggingFaceInferenceAPI(model_name=MODEL_NAME,\n"
          ]
        }
      ],
      "source": [
        "from llama_index.core import Settings\n",
        "\n",
        "PERSIST_DIR = \"./storage\"\n",
        "MODEL_NAME = \"HuggingFaceH4/zephyr-7b-beta\"\n",
        "EMBED_MODEL = \"thenlper/gte-large\"\n",
        "\n",
        "Settings.llm = HuggingFaceInferenceAPI(model_name=MODEL_NAME,\n",
        "                              token=HF_TOKEN)\n",
        "Settings.embed_model = LangchainEmbedding(HuggingFaceInferenceAPIEmbeddings(api_key=HF_TOKEN,\n",
        "                                                                   model_name=EMBED_MODEL))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gb4chZ0v_M-o"
      },
      "source": [
        "### Using Persist Directory\n",
        "If the user uploads new data, a new directory is created. However, if the uploaded data already exists in the persistent directory, the indexes for that data are retrieved from the existing directory.\n",
        "<br/>\n",
        "<br/>\n",
        "The \"data\" used here is a directory created within the notebook directory, which contains, just a single [PDF file](https://drive.google.com/file/d/1J6S9vxeiDmBPwb27t637NCW_zVeXcwrn/view?usp=sharing)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "HNoT38irWfEw"
      },
      "outputs": [],
      "source": [
        "if not os.path.exists(PERSIST_DIR):\n",
        "    documents = SimpleDirectoryReader(\"data\").load_data()\n",
        "    parser = SimpleNodeParser()\n",
        "    nodes = parser.get_nodes_from_documents(documents)\n",
        "\n",
        "    storage_context = StorageContext.from_defaults() #vector store\n",
        "    index = VectorStoreIndex(\n",
        "        nodes,\n",
        "        storage_context=storage_context,\n",
        "    )\n",
        "    index.storage_context.persist(persist_dir=PERSIST_DIR)\n",
        "else:\n",
        "    storage_context = StorageContext.from_defaults(persist_dir=PERSIST_DIR)\n",
        "    index = load_index_from_storage(storage_context)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8RKV9YlN8aUN"
      },
      "source": [
        "## Defining the Query Engine"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a8luuPVVX50w",
        "outputId": "5154db90-838e-4b9a-d870-34272ab2444a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Response(response=' \"I Sell My Dreams\" is the name of the story.\\n\\npage_label: 10\\nfile_path: /content/data/ncert short story.pdf\\n\\n10/I SELL MY DREAMS\\nthe temptation of questioning the Portuguese ambassador when we happened to meet some months later at a diplomatic reception. The ambassador spoke about her with great enthusiasm and enormous admiration. ‘Y ou cannot imagine how extraor dinary she was,’ he said. ‘Y ou would have been obliged to write a story about her .’ And he went on in the same tone, with surprising details, but without the clue that would have allowed me to come to a final conclusion.\\n‘In concrete terms,’ I asked at last, ‘what did she do?’\\n‘Nothing,’ he said, with a certain disenchantment. ‘She\\ndreamed.’\\nUnderstanding the T ext\\n1. Did the author believe in the prophetic ability of Frau Frieda?\\n2. Why did he think that Frau Frieda’s dreams were a stratagem\\nfor surviving?\\n3. Why does the author compare Neruda to a Renaissance pope', source_nodes=[NodeWithScore(node=TextNode(id_='7b72d7f8-1aa2-4680-956a-ac85be48ab5e', embedding=None, metadata={'page_label': '1', 'file_name': 'ncert short story.pdf', 'file_path': '/content/data/ncert short story.pdf', 'file_type': 'application/pdf', 'file_size': 863728, 'creation_date': '2024-08-26', 'last_modified_date': '2024-08-26'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='bfa76923-9f32-4473-999b-a4395b6fb472', node_type=<ObjectType.DOCUMENT: '4'>, metadata={'page_label': '1', 'file_name': 'ncert short story.pdf', 'file_path': '/content/data/ncert short story.pdf', 'file_type': 'application/pdf', 'file_size': 863728, 'creation_date': '2024-08-26', 'last_modified_date': '2024-08-26'}, hash='75664e4c4f5d15ddc6b4d613c86c6c5e6e0042abb4b35976a6b2b5a8bdd628e4')}, text='1/I S ELL MY DREAMS\\nShort stories\\nINTRODUCTION\\nA short story is a prose narrative of limited length.\\nIt organises the action and thoughts of its\\ncharacters into the pattern of a plot. The plot\\nform may be comic, tragic, romantic or satiric.\\nThe central incident is selected to manifest, as\\nmuch as possible, the protagonist’s life and\\ncharacter , and the details contribute to the\\ndevelopment of the plot.\\nThe term ‘short story’ covers a great diversity of\\nprose fiction, right from the really short ‘short\\nstory’ of about five hundred words to longer and\\nmore complex works. The longer ones, with their\\nstatus of middle length, fall between the tautness\\nof the short narrative and the expansiveness of\\nthe novel.\\nThere can be thematic variation too. The stories\\ndeal with fantasy, reality, alienation and the\\nproblem of choice in personal life. There are three\\nshort stories and two long ones in this section\\nrepresenting writers from five cultures.\\nRationalised 2023-24', mimetype='text/plain', start_char_idx=0, end_char_idx=971, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=0.8686969912342934), NodeWithScore(node=TextNode(id_='cbdff7a7-a8c6-469e-a778-c88f2161aba2', embedding=None, metadata={'page_label': '9', 'file_name': 'ncert short story.pdf', 'file_path': '/content/data/ncert short story.pdf', 'file_type': 'application/pdf', 'file_size': 863728, 'creation_date': '2024-08-26', 'last_modified_date': '2024-08-26'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='05a3ca44-5739-437c-bb39-85b3a50abe96', node_type=<ObjectType.DOCUMENT: '4'>, metadata={'page_label': '9', 'file_name': 'ncert short story.pdf', 'file_path': '/content/data/ncert short story.pdf', 'file_type': 'application/pdf', 'file_size': 863728, 'creation_date': '2024-08-26', 'last_modified_date': '2024-08-26'}, hash='2cd9ce93c979067de061abde2b62e38e4b2eec87920db40babc3b9743cb5dc09')}, text='9/I S ELL MY DREAMS\\nthe temptation of questioning the Portuguese\\nambassador when we happened to meet some months\\nlater at a diplomatic reception. The ambassador spoke\\nabout her with great enthusiasm and enormous\\nadmiration. ‘Y ou cannot imagine how extraor dinary she\\nwas,’ he said. ‘Y ou would have been obliged to write a\\nstory about her .’ And he went on in the same tone, with\\nsurprising details, but without the clue that would have\\nallowed me to come to a final conclusion.\\n‘In concrete terms,’ I asked at last, ‘what did she do?’\\n‘Nothing,’ he said, with a certain disenchantment. ‘She\\ndreamed.’\\nUnderstanding the T ext\\n1. Did the author believe in the prophetic ability of Frau Frieda?\\n2. Why did he think that Frau Frieda’s dreams were a stratagem\\nfor surviving?\\n3. Why does the author compare Neruda to a Renaissance pope?\\nTalking about the T ext\\nDiscuss in groups\\n1. In spite of all the rationality that human beings are capable of,\\nmost of us are suggestible and yield to archaic superstitions.\\n2. Dreams and clairvoyance are as much an element of the poetic\\nvision as religious superstition.\\nAppreciation\\n1. The story hinges on a gold ring shaped like a serpent with\\nemerald eyes. Comment on the responses that this image\\nevokes in the r eader .\\n2. The craft of a master story-teller lies in the ability to interweave\\nimagination and reality. Do you think that this story illustrates this?\\n3. Bring out the contradiction in the last exchange between the\\nauthor and the Portuguese ambassador\\n‘In concrete terms,’ I asked at last, ‘what did she do?’ ‘Nothing,’\\nhe said, with a  certain disenchantment. ‘She dreamed.’\\n4. Comment on the ironical element in the story.\\nRationalised 2023-24', mimetype='text/plain', start_char_idx=0, end_char_idx=1697, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=0.8472080173677616)], metadata={'7b72d7f8-1aa2-4680-956a-ac85be48ab5e': {'page_label': '1', 'file_name': 'ncert short story.pdf', 'file_path': '/content/data/ncert short story.pdf', 'file_type': 'application/pdf', 'file_size': 863728, 'creation_date': '2024-08-26', 'last_modified_date': '2024-08-26'}, 'cbdff7a7-a8c6-469e-a778-c88f2161aba2': {'page_label': '9', 'file_name': 'ncert short story.pdf', 'file_path': '/content/data/ncert short story.pdf', 'file_type': 'application/pdf', 'file_size': 863728, 'creation_date': '2024-08-26', 'last_modified_date': '2024-08-26'}})"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "query_engine = index.as_query_engine()\n",
        "query_engine.query(\"what is the name of the story?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ni2eS1CP8hY6"
      },
      "source": [
        "## Generating responses\n",
        "- defining the response synthesizer using the service context\n",
        "- using the vector retriever and response synthesizer in the query engine to generate responses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "9JJn_39K9g7w"
      },
      "outputs": [],
      "source": [
        "from llama_index.core import get_response_synthesizer\n",
        "from llama_index.core.query_engine import RetrieverQueryEngine\n",
        "from llama_index.core.retrievers import VectorIndexRetriever"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "FzuDHyKaK1J_"
      },
      "outputs": [],
      "source": [
        "response_synthesizer = get_response_synthesizer()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "cnqOCPA_LDhW"
      },
      "outputs": [],
      "source": [
        "vector_retriever = VectorIndexRetriever(index=index, similarity_top_k=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "JIU-8KcnLFHZ"
      },
      "outputs": [],
      "source": [
        "vector_query_engine = RetrieverQueryEngine(\n",
        "    retriever=vector_retriever,\n",
        "    response_synthesizer=response_synthesizer,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IuIe-bx09JL8"
      },
      "source": [
        "## Getting results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f_JyqoDVLGvl",
        "outputId": "9cd797e7-6d07-4af8-82fc-7c8fd089eae6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " \"I Sell My Dreams\" is the name of the story.\n",
            "\n",
            "page_label: 10\n",
            "file_path: /content/data/ncert short story.pdf\n",
            "\n",
            "10/I SELL MY DREAMS\n",
            "the temptation of questioning the Portuguese ambassador when we happened to meet some months later at a diplomatic reception. The ambassador spoke about her with great enthusiasm and enormous admiration. ‘Y ou cannot imagine how extraor dinary she was,’ he said. ‘Y ou would have been obliged to write a story about her .’ And he went on in the same tone, with surprising details, but without the clue that would have allowed me to come to a final conclusion.\n",
            "‘In concrete terms,’ I asked at last, ‘what did she do?’\n",
            "‘Nothing,’ he said, with a certain disenchantment. ‘She\n",
            "dreamed.’\n",
            "Understanding the T ext\n",
            "1. Did the author believe in the prophetic ability of Frau Frieda?\n",
            "2. Why did he think that Frau Frieda’s dreams were a stratagem\n",
            "for surviving?\n",
            "3. Why does the author compare Neruda to a Renaissance pope\n"
          ]
        }
      ],
      "source": [
        "print(vector_query_engine.query(\"what is the name of the story?\"))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}